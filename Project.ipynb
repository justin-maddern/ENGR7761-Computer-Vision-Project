{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79566281-a1b4-4385-bb50-ca44f4203fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\madde\\anaconda3\\Lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated and will be removed in a future release\n",
      "  \"class\": algorithms.Blowfish,\n"
     ]
    }
   ],
   "source": [
    "# these imports let you use opencv\n",
    "import cv2 #opencv itself\n",
    "#import common #some useful opencv functions\n",
    "#import video # some video stuff\n",
    "import numpy as np # matrix manipulations\n",
    "import sys\n",
    "import math\n",
    "\n",
    "#the following are to do with this interactive notebook code\n",
    "%matplotlib inline \n",
    "from matplotlib import pyplot as plt # this lets you draw inline pictures in the notebooks\n",
    "import pylab # this allows you to control figure size \n",
    "pylab.rcParams['figure.figsize'] = (10.0, 8.0) # this controls figure size in the notebook\n",
    "from skimage import data\n",
    "from skimage.util.dtype import dtype_range\n",
    "from skimage.util import img_as_ubyte\n",
    "from skimage import exposure\n",
    "from skimage.morphology import disk\n",
    "from skimage.morphology import ball\n",
    "from skimage.filters import rank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5d33b8-cbb8-4a14-b33f-f6c96297d6ac",
   "metadata": {},
   "source": [
    "# Ball Tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52db655d-0491-4fc1-8c1f-43aef05f4ea2",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bafb9bb4-8a4f-42f3-b520-50d8962285a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('eval clip big 2.mp4') # capturing the video in a variable\n",
    "flag, cap_f = cap.read() # get an initial frame\n",
    "fbuffer=10\n",
    "alpha=float(0.9/fbuffer) \n",
    "difference_thresh=1\n",
    "movingaverage=np.float32(cap_f)\n",
    "\n",
    "# Define the codec and create a VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'H264')  # Codec for AVI format\n",
    "fps = 60.0  # Frames per second\n",
    "width, height = 1920, 1080  # Frame size\n",
    "output_size = (width, height)\n",
    "out = cv2.VideoWriter('repport big dilat eval.mp4', fourcc, fps, output_size)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read() # capturing the video frame by frame for processing\n",
    "    if not ret:\n",
    "        break  # Break the loop if no more frames are available\n",
    "        \n",
    "    og_resize = frame[0:1080, 0:1920]\n",
    "    cv2.accumulateWeighted(frame,movingaverage,alpha)\n",
    "    res = cv2.convertScaleAbs(movingaverage)\n",
    "    diff = cv2.absdiff(res, frame) #comparing res to frame\n",
    "\n",
    "    frame_resize = diff[0:1080, 0:1920]\n",
    "    # Equalization\n",
    "    gray = cv2.cvtColor(frame_resize, cv2.COLOR_RGB2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray,(9,9),0)\n",
    "    ret,th = cv2.threshold(blur,15,255,cv2.THRESH_BINARY)\n",
    "    dilat = cv2.dilate(th,(7,7),iterations=2)\n",
    "    # footprint = disk(30)\n",
    "    # img_local_eq = rank.equalize(th, footprint=footprint)\n",
    "    # img_glob_eq = exposure.equalize_hist(th)\n",
    "\n",
    "    # final = cv2.bitwise_and(frame_resize,dilat)\n",
    "\n",
    "\n",
    "    out.write(dilat)\n",
    "    cv2.imshow('Video', dilat)\n",
    "    \n",
    "    if cv2.waitKey(70) & 0xFF == ord('q'): #Waitkey(num): num sets the delay for processing between each frame\n",
    "        break  # Press 'q' to exit the loop\n",
    "\n",
    "# Release the video capture object and close the window\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6fd7de-0303-4c60-816e-1ba9e3ddc5bd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Initial LK Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "1eef1ed4-4a08-4c53-acdd-a21b90319a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load video frames (or use webcam feed)\n",
    "cap = cv2.VideoCapture(\"project output.mp4\")\n",
    "\n",
    "# params for corner detection \n",
    "feature_params = dict( maxCorners = 80, qualityLevel = 0.7, minDistance = 20, blockSize = 15 ) \n",
    "  \n",
    "# Parameters for lucas kanade optical flow \n",
    "lk_params = dict( winSize = (10,10), maxLevel = 20, criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 50, 0.9)) \n",
    "  \n",
    "# Create some random colors \n",
    "color = np.random.randint(0, 255, (100, 3)) \n",
    "  \n",
    "# Take first frame and find corners in it \n",
    "ret, old_frame = cap.read() \n",
    "old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY) \n",
    "p0 = cv2.goodFeaturesToTrack(old_gray, mask = None, **feature_params) \n",
    "  \n",
    "# Create a mask image for drawing purposes \n",
    "mask = np.zeros_like(old_frame) \n",
    "  \n",
    "while(1): \n",
    "      \n",
    "    ret, frame = cap.read() \n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) \n",
    "  \n",
    "    # calculate optical flow \n",
    "    p0 = cv2.goodFeaturesToTrack(old_gray, mask = None, **feature_params) \n",
    "    p1, st, err = cv2.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params) \n",
    "  \n",
    "    # Select good points\n",
    "    good_new = p1[st == 1] \n",
    "    good_old = p0[st == 1] \n",
    "  \n",
    "    # draw the tracks \n",
    "    for i, (new, old) in enumerate(zip(good_new,  good_old)): \n",
    "        a, b = new.ravel().astype(int) \n",
    "        c, d = old.ravel().astype(int)\n",
    "        mask = cv2.line(mask, (a, b), (c, d), color[i].tolist(), 2) \n",
    "          \n",
    "        frame = cv2.circle(frame, (a, b), 5, color[i].tolist(), -1) \n",
    "          \n",
    "    img = cv2.add(frame, mask) \n",
    "  \n",
    "    cv2.imshow('frame', img) \n",
    "      \n",
    "    if cv2.waitKey(50) & 0xFF == ord('q'): #Waitkey(num): num sets the delay for processing between each frame\n",
    "        break\n",
    "  \n",
    "    # Updating Previous frame and points  \n",
    "    old_gray = frame_gray.copy() \n",
    "    p0 = good_new.reshape(-1, 1, 2) \n",
    "  \n",
    "cv2.destroyAllWindows() \n",
    "cap.release() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376c1a6a-6631-4ed5-9ea5-ac4d6faa4730",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## LK Tracking P2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "id": "6a62f88c-e71c-42ca-9fe3-98c8a4228712",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Parameters for ShiTomasi corner detection\n",
    "feature_params = dict(maxCorners=200,\n",
    "                      qualityLevel=0.01,\n",
    "                      minDistance=7,\n",
    "                      blockSize=7)\n",
    "\n",
    "# Parameters for Lucas-Kanade optical flow\n",
    "lk_params = dict(winSize=(21, 21),\n",
    "                 maxLevel=3,\n",
    "                 criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "# Capture the video from a file or camera\n",
    "cap = cv2.VideoCapture('project output.mp4')\n",
    "\n",
    "# Define the codec and create a VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'H264')  # Codec for AVI format\n",
    "fps = 60.0  # Frames per second\n",
    "width, height = 1920, 1080  # Frame size\n",
    "output_size = (width, height)\n",
    "out = cv2.VideoWriter('Method L-K.mp4', fourcc, fps, output_size)\n",
    "\n",
    "# Read the first frame\n",
    "ret, old_frame = cap.read()\n",
    "old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Find initial points to track\n",
    "p0 = cv2.goodFeaturesToTrack(old_gray, mask=None, **feature_params)\n",
    "\n",
    "# Create a mask image for drawing purposes\n",
    "\n",
    "mask = np.zeros_like(old_frame)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Calculate optical flow\n",
    "    p0 = cv2.goodFeaturesToTrack(old_gray, mask=None, **feature_params)\n",
    "    p1, st, err = cv2.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params)\n",
    "\n",
    "    # Select good points\n",
    "    good_new = p1[st == 1]\n",
    "    good_old = p0[st == 1]\n",
    "\n",
    "    # Draw the tracks\n",
    "    for i, (new, old) in enumerate(zip(good_new, good_old)):\n",
    "        a, b = new.ravel().astype(int)\n",
    "        c, d = old.ravel().astype(int)\n",
    "        mask = cv2.line(mask, (a, b), (c, d), (0, 255, 0), 2)\n",
    "        # frame = cv2.circle(frame, (a, b), 5, (0, 0, 255), -1)\n",
    "\n",
    "    img = cv2.add(frame, mask)\n",
    "\n",
    "    out.write(img)\n",
    "    cv2.imshow('frame', img)\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "    # Update the previous frame and previous points\n",
    "    old_gray = frame_gray.copy()\n",
    "    p0 = good_new.reshape(-1, 1, 2)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "out.release()\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f83ab1-b6f0-4c4d-8d9e-307313488870",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## LK with Circles (Doesnt Work)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "id": "6ad01ee6-73ce-47b0-9b5e-18d3aa01fea8",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\hough.cpp:2269: error: (-215:Assertion failed) !_image.empty() && _image.type() == CV_8UC1 && (_image.isMat() || _image.isUMat()) in function 'cv::HoughCircles'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[560], line 34\u001b[0m\n\u001b[0;32m     31\u001b[0m frame_gray \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(frame, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2GRAY)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Detect circles in the current frame\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m current_circle \u001b[38;5;241m=\u001b[39m detect_circle(frame_gray)\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m current_circle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     36\u001b[0m     p0 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([[current_circle[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m], current_circle[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m]]], dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n",
      "Cell \u001b[1;32mIn[560], line 11\u001b[0m, in \u001b[0;36mdetect_circle\u001b[1;34m(frame_gray)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdetect_circle\u001b[39m(frame_gray):\n\u001b[1;32m---> 11\u001b[0m     circles \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mHoughCircles(img,cv2\u001b[38;5;241m.\u001b[39mHOUGH_GRADIENT, dp\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, minDist\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m45\u001b[39m,param1\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m58\u001b[39m,param2\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m37\u001b[39m,minRadius\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m,maxRadius\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m)\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m circles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     13\u001b[0m         circles \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mround(circles[\u001b[38;5;241m0\u001b[39m, :])\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mint\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\hough.cpp:2269: error: (-215:Assertion failed) !_image.empty() && _image.type() == CV_8UC1 && (_image.isMat() || _image.isUMat()) in function 'cv::HoughCircles'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Parameters for Lucas-Kanade optical flow\n",
    "lk_params = dict(winSize=(15,15),\n",
    "                 maxLevel=8,\n",
    "                 criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 30, 0.03))\n",
    "\n",
    "# Function to detect circles using Hough Circle Transform\n",
    "def detect_circle(frame_gray):\n",
    "    circles = cv2.HoughCircles(img,cv2.HOUGH_GRADIENT, dp=2, minDist=45,param1=58,param2=37,minRadius=15,maxRadius=30)\n",
    "    if circles is not None:\n",
    "        circles = np.round(circles[0, :]).astype(\"int\")\n",
    "        return circles\n",
    "    return None\n",
    "\n",
    "# Capture the video from a file or camera\n",
    "cap = cv2.VideoCapture('project output.mp4')\n",
    "\n",
    "# Read the first frame\n",
    "ret, old_frame = cap.read()\n",
    "old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Create a mask image for drawing purposes\n",
    "mask = np.zeros_like(old_frame)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect circles in the current frame\n",
    "    current_circle = detect_circle(frame_gray)\n",
    "    if current_circle is not None:\n",
    "        p0 = np.array([[current_circle[0][0], current_circle[0][1]]], dtype=np.float32).reshape(-1, 1, 2)\n",
    "    else:\n",
    "        print(\"No circles detected in the current frame.\")\n",
    "        continue  # Skip this frame if no circles are found\n",
    "\n",
    "    # Calculate optical flow\n",
    "    p1, st, err = cv2.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params)\n",
    "\n",
    "    # Select good points\n",
    "    good_new = p1[st == 1]\n",
    "    good_old = p0[st == 1]\n",
    "\n",
    "    # Draw the tracks\n",
    "    for i, (new, old) in enumerate(zip(good_new, good_old)):\n",
    "        a, b = new.ravel().astype(int)\n",
    "        c, d = old.ravel().astype(int)\n",
    "        mask = cv2.line(mask, (a, b), (c, d), (0, 255, 0), 2)\n",
    "        frame = cv2.circle(frame, (a, b), 5, (0, 0, 255), -1)\n",
    "\n",
    "    img = cv2.add(frame, mask)\n",
    "\n",
    "    cv2.imshow('frame', img)\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "    # Update the previous frame and previous points\n",
    "    old_gray = frame_gray.copy()\n",
    "    p0 = good_new.reshape(-1, 1, 2)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5f2676-a073-4cc8-966c-52b50705f216",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## LK with Circles P2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "id": "c4b97d41-c2dd-4116-b2e8-8ffc4e443b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Parameters for Lucas-Kanade optical flow\n",
    "lk_params = dict(winSize=(21, 21),\n",
    "                 maxLevel=3,\n",
    "                 criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 30, 0.03))\n",
    "\n",
    "# Function to detect circles using Hough Circle Transform\n",
    "def detect_circle(frame_gray):\n",
    "    circles = cv2.HoughCircles(frame_gray,cv2.HOUGH_GRADIENT, dp=2, minDist=45,param1=58,param2=37,minRadius=10,maxRadius=58)\n",
    "    if circles is not None:\n",
    "        circles = np.round(circles[0, :]).astype(\"int\")\n",
    "        return circles\n",
    "    return None\n",
    "\n",
    "# Capture the video from a file or camera\n",
    "cap = cv2.VideoCapture('project output.mp4')\n",
    "\n",
    "# Define the codec and create a VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'H264')  # Codec for AVI format\n",
    "fps = 60.0  # Frames per second\n",
    "width, height = 1920, 1080  # Frame size\n",
    "output_size = (width, height)\n",
    "out = cv2.VideoWriter('Method L-K with Circles.mp4', fourcc, fps, output_size)\n",
    "\n",
    "# Read the first frame\n",
    "ret, old_frame = cap.read()\n",
    "old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Create a mask image for drawing purposes\n",
    "mask = np.zeros_like(old_frame)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect circles in the current frame\n",
    "    current_circle = detect_circle(frame_gray)\n",
    "    if current_circle is not None:\n",
    "        p0 = np.array([[current_circle[0][0], current_circle[0][1]]], dtype=np.float32).reshape(-1, 1, 2)\n",
    "    else:\n",
    "        # If no circles are found, continue to the next frame\n",
    "        continue\n",
    "\n",
    "    # Calculate optical flow\n",
    "    p1, st, err = cv2.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params)\n",
    "\n",
    "    # Select good points\n",
    "    good_new = p1[st == 1]\n",
    "    good_old = p0[st == 1]\n",
    "\n",
    "    # Draw the tracks\n",
    "    for i, (new, old) in enumerate(zip(good_new, good_old)):\n",
    "        a, b = new.ravel().astype(int)\n",
    "        c, d = old.ravel().astype(int)\n",
    "        mask = cv2.line(mask, (a, b), (c, d), (0, 255, 0), 2)\n",
    "        frame = cv2.circle(frame, (a, b), 5, (0, 0, 255), -1)\n",
    "\n",
    "    img = cv2.add(frame, mask)\n",
    "\n",
    "    out.write(img)\n",
    "    cv2.imshow('frame', img)\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "    # Update the previous frame and previous points\n",
    "    old_gray = frame_gray.copy()\n",
    "    p0 = good_new.reshape(-1, 1, 2)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "out.release()\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da68e5a-ac4f-40a2-a274-ee72ffe3d4c3",
   "metadata": {},
   "source": [
    "## Hough Circle only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d01c1c-2a9b-4798-81bc-d9857bd8fdd7",
   "metadata": {},
   "source": [
    "### Smaller Circles\n",
    "\n",
    "Better for gameplay "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af55fbd1-e605-4c02-a7e5-b0af1a0becff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\madde\\AppData\\Local\\Temp\\ipykernel_31892\\1138968047.py:12: RuntimeWarning: overflow encountered in scalar subtract\n",
      "  dist = lambda x1,y1,x2,y2: (x1-x2)**2 + (y1-y2)**2\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture('repport big dilat eval.mp4')\n",
    "cap2 = cv2.VideoCapture('eval clip big 2.mp4')\n",
    "\n",
    "# Define the codec and create a VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'H264')  # Codec for AVI format\n",
    "fps = 60.0  # Frames per second\n",
    "width, height = 1920, 1080  # Frame size\n",
    "output_size = (width, height)\n",
    "out = cv2.VideoWriter('repport big circle.mp4', fourcc, fps, output_size)\n",
    "\n",
    "prevCircle = None\n",
    "dist = lambda x1,y1,x2,y2: (x1-x2)**2 + (y1-y2)**2\n",
    "\n",
    "while True:\n",
    "    ret2,frame2 = cap2.read()\n",
    "    ret1,frame = cap.read()\n",
    "    \n",
    "    if not ret1: break\n",
    "    if not ret2: break\n",
    "\n",
    "    grayFrame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    blurFrame = cv2.GaussianBlur(grayFrame, (21,21),0)\n",
    "\n",
    "    circles = cv2.HoughCircles(grayFrame ,cv2.HOUGH_GRADIENT, dp=1.4, minDist=100,\n",
    "                               param1=80,param2=17,minRadius=5,maxRadius=20)\n",
    "    \n",
    "    if circles is not None:\n",
    "        circles = np.uint16(np.around(circles))\n",
    "        chosen = None\n",
    "        for i in circles[0, :]:\n",
    "            if chosen is None: chosen = i\n",
    "            if prevCircle is not None:\n",
    "                if dist(chosen[0], chosen[1],prevCircle[0],prevCircle[1]) <= dist(i[0],i[1],prevCircle[0],prevCircle[1]):\n",
    "                    chosen = i\n",
    "        cv2.circle(frame2, (chosen[0], chosen[1]), 1, (0,100,100), 3)\n",
    "        cv2.circle(frame2, (chosen[0], chosen[1]), chosen[2], (255,0,255), 3)\n",
    "        prevCircle = chosen\n",
    "\n",
    "    out.write(frame2)\n",
    "    cv2.imshow(\"circles\", frame2)\n",
    "\n",
    "    if cv2.waitKey(70) & 0xFF == ord('q'): break\n",
    "\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "out.release()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4027345-a607-44f7-866d-faa9c78b91e1",
   "metadata": {},
   "source": [
    "### Big Circles\n",
    "\n",
    "Footage more zoomed in requiring larger circle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "id": "d314c811-f60f-4274-8523-689cf093034a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\madde\\AppData\\Local\\Temp\\ipykernel_23032\\68478830.py:14: RuntimeWarning: overflow encountered in scalar subtract\n",
      "  dist = lambda x1,y1,x2,y2: (x1-x2)**2 + (y1-y2)**2\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture('test output.mp4')\n",
    "cap2 = cv2.VideoCapture('Left2Right.MOV')\n",
    "\n",
    "# Define the codec and create a VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'H264')  # Codec for AVI format\n",
    "fps = 60.0  # Frames per second\n",
    "width, height = 1920, 1080  # Frame size\n",
    "output_size = (width, height)\n",
    "out = cv2.VideoWriter('Result L2R.mp4', fourcc, fps, output_size)\n",
    "\n",
    "length = int(cap2.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print(length)\n",
    "prevCircle = None\n",
    "dist = lambda x1,y1,x2,y2: (x1-x2)**2 + (y1-y2)**2\n",
    "\n",
    "while True:\n",
    "    ret,frame = cap.read()\n",
    "    ret2,frame2 = cap2.read()\n",
    "    if not ret: break\n",
    "    if not ret2: break\n",
    "\n",
    "    grayFrame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    blurFrame = cv2.GaussianBlur(grayFrame, (21,21),0)\n",
    "\n",
    "    circles = cv2.HoughCircles(grayFrame ,cv2.HOUGH_GRADIENT, dp=1.4, minDist=100,\n",
    "                               param1=100,param2=25,minRadius=12,maxRadius=58)\n",
    "    \n",
    "    if circles is not None:\n",
    "        circles = np.uint16(np.around(circles))\n",
    "        chosen = None\n",
    "        for i in circles[0, :]:\n",
    "            if chosen is None: chosen = i\n",
    "            if prevCircle is not None:\n",
    "                if dist(chosen[0], chosen[1],prevCircle[0],prevCircle[1]) <= dist(i[0],i[1],prevCircle[0],prevCircle[1]):\n",
    "                    chosen = i\n",
    "        cv2.circle(frame2, (chosen[0], chosen[1]), 1, (0,100,100), 3)\n",
    "        cv2.circle(frame2, (chosen[0], chosen[1]), chosen[2], (255,0,255), 3)\n",
    "        prevCircle = chosen\n",
    "        \n",
    "    cv2.namedWindow(\"circles\", cv2.WINDOW_NORMAL)\n",
    "    cv2.resizeWindow(\"circles\", 2000, 1500)\n",
    "    out.write(frame2)\n",
    "    cv2.imshow(\"circles\", frame2)\n",
    "    \n",
    "\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'): break\n",
    "\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "out.release()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0303d40-d64e-4191-9646-c8f4c90405bf",
   "metadata": {},
   "source": [
    "# Line Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "id": "34c9fd1c-a618-4062-aa75-2d329772ec50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(argv):\n",
    "    default_file = 'CV clip.mp4'  # This is not useful\n",
    "    filename = argv[0] if len(argv) > 0 else default_file\n",
    "\n",
    "    # Open the video file\n",
    "    cap = cv2.VideoCapture('CV input.mp4')\n",
    "\n",
    "    # Define the codec and create a VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'H264')  # Codec for AVI format\n",
    "    fps = 60.0  # Frames per second\n",
    "    width, height = 1920, 1080  # Frame size\n",
    "    output_size = (width, height)\n",
    "    out = cv2.VideoWriter('Results Lines.mp4', fourcc, fps, output_size)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print('Error opening video file!')\n",
    "        return -1\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break  # End of video\n",
    "\n",
    "        # Convert frame to grayscale\n",
    "        r_frame = frame[0:1080, 0:1920]\n",
    "        src = cv2.cvtColor(r_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Apply Canny edge detection\n",
    "        dst = cv2.Canny(src, 200, 255, None, 3)\n",
    "\n",
    "        # Copy edges to the images that will display the results in BGR\n",
    "        cdst = cv2.cvtColor(dst, cv2.COLOR_GRAY2BGR)\n",
    "        cdstP = np.copy(cdst)\n",
    "\n",
    "        # Hough line detection\n",
    "        lines = cv2.HoughLines(dst, 1, np.pi / 80, 200, None, 0, 0)\n",
    "        if lines is not None:\n",
    "            for i in range(len(lines)):\n",
    "                rho = lines[i][0][0]\n",
    "                theta = lines[i][0][1]\n",
    "                a = math.cos(theta)\n",
    "                b = math.sin(theta)\n",
    "                x0 = a * rho\n",
    "                y0 = b * rho\n",
    "                pt1 = (int(x0 + 1000 * (-b)), int(y0 + 1000 * (a)))\n",
    "                pt2 = (int(x0 - 1000 * (-b)), int(y0 - 1000 * (a)))\n",
    "                cv2.line(cdst, pt1, pt2, (0, 0, 255), 3, cv2.LINE_AA)\n",
    "\n",
    "        # Hough line detection (probabilistic)\n",
    "        linesP = cv2.HoughLinesP(dst, 0.4, np.pi / 80, 200, None, 180, 62)\n",
    "        if linesP is not None:\n",
    "            for i in range(len(linesP)):\n",
    "                l = linesP[i][0]\n",
    "                # cv2.line(frame, (l[0], l[1]), (l[2], l[3]), (0, 0, 255), 3, cv2.LINE_AA)\n",
    "\n",
    "        # Display results\n",
    "\n",
    "        out.write(frame)\n",
    "        cv2.imshow('Fully lined', frame) #correct length lines\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return 0\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(sys.argv[1:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa7f641-a2ab-43f8-9ad6-3434aa647513",
   "metadata": {},
   "source": [
    "# Merging Circles and Lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "id": "4c4acdaf-f948-441c-b40d-a933262d66a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\madde\\AppData\\Local\\Temp\\ipykernel_23032\\3142273687.py:14: RuntimeWarning: overflow encountered in scalar subtract\n",
      "  dist = lambda x1,y1,x2,y2: (x1-x2)**2 + (y1-y2)**2\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture('Demo Pres.mp4')\n",
    "cap2 = cv2.VideoCapture('CV input.mp4')\n",
    "\n",
    "# Define the codec and create a VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'H264')  # Codec for AVI format\n",
    "fps = 60.0  # Frames per second\n",
    "width, height = 1920, 1080  # Frame size\n",
    "output_size = (width, height)\n",
    "out = cv2.VideoWriter('Demo final.mp4', fourcc, fps, output_size)\n",
    "\n",
    "length = int(cap2.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print(length)\n",
    "prevCircle = None\n",
    "dist = lambda x1,y1,x2,y2: (x1-x2)**2 + (y1-y2)**2\n",
    "\n",
    "while True:\n",
    "    ret2,frame2 = cap2.read() #original footage\n",
    "    ret1,frame = cap.read() #processed footage for circle tracking\n",
    "    \n",
    "    if not ret1: break\n",
    "    if not ret2: break\n",
    "\n",
    "    grayFrame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    src = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "    blurFrame = cv2.GaussianBlur(grayFrame, (21,21),0)\n",
    "\n",
    "    circles = cv2.HoughCircles(grayFrame ,cv2.HOUGH_GRADIENT, dp=1.4, minDist=100,\n",
    "                               param1=70,param2=17,minRadius=5,maxRadius=20)\n",
    "    dst = cv2.Canny(src, 200, 255, None, 3)\n",
    "    \n",
    "    if circles is not None:\n",
    "        circles = np.uint16(np.around(circles))\n",
    "        chosen = None\n",
    "        for i in circles[0, :]:\n",
    "            if chosen is None: chosen = i\n",
    "            if prevCircle is not None:\n",
    "                if dist(chosen[0], chosen[1],prevCircle[0],prevCircle[1]) <= dist(i[0],i[1],prevCircle[0],prevCircle[1]):\n",
    "                    chosen = i\n",
    "        cv2.circle(frame2, (chosen[0], chosen[1]), 1, (0,100,100), 3)\n",
    "        cv2.circle(frame2, (chosen[0], chosen[1]), chosen[2], (255,0,255), 3)\n",
    "        prevCircle = chosen\n",
    "\n",
    "    # Hough line detection (probabilistic)\n",
    "    linesP = cv2.HoughLinesP(dst, 0.4, np.pi / 80, 200, None, 180, 100)\n",
    "    if linesP is not None:\n",
    "        for i in range(len(linesP)):\n",
    "            l = linesP[i][0]\n",
    "            cv2.line(frame2, (l[0], l[1]), (l[2], l[3]), (0, 0, 255), 3, cv2.LINE_AA)\n",
    "       \n",
    "    # cv2.namedWindow(\"circles\", cv2.WINDOW_NORMAL)\n",
    "    # cv2.resizeWindow(\"circles\", 2000, 1500)\n",
    "    out.write(frame2)\n",
    "    cv2.imshow(\"circles\", frame2)\n",
    "    \n",
    "    if cv2.waitKey(5) & 0xFF == ord('q'): break\n",
    "    \n",
    "cv2.destroyAllWindows()\n",
    "out.release()\n",
    "cap.release()\n",
    "cap2.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2a5f93-68b3-4ae4-be48-31da99a44c66",
   "metadata": {},
   "source": [
    "Polygon of inside the cour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "id": "ed2d662c-e21b-41d7-a9c2-b3594bc8dedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def region_of_interest(img, vertices):\n",
    "    # Define a blank matrix that matches the image height/width.\n",
    "    mask = np.zeros_like(img)\n",
    "    # Retrieve the number of color channels of the image.\n",
    "    channel_count = img.shape[2]\n",
    "    # Create a match color with the same color channel counts.\n",
    "    match_mask_color = (255,) * channel_count\n",
    "      \n",
    "    # Fill inside the polygon\n",
    "    cv2.fillPoly(mask, vertices, match_mask_color)\n",
    "    \n",
    "    # Returning the image only where mask pixels match\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "\n",
    "region_of_interest_vertices = [\n",
    "    (1550, 800),\n",
    "    (1170,582),\n",
    "    (783,573),\n",
    "    (368,800),\n",
    "]\n",
    "\n",
    "image = cv2.imread('Capture1.PNG')\n",
    "cap2 = cv2.VideoCapture('CV input.mp4')\n",
    "\n",
    "# Define the codec and create a VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'H264')  # Codec for AVI format\n",
    "fps = 60.0  # Frames per second\n",
    "width, height = 1920, 1080  # Frame size\n",
    "output_size = (width, height)\n",
    "out = cv2.VideoWriter('Method Polygon.mp4', fourcc, fps, output_size)\n",
    "\n",
    "while True:\n",
    "    ret,frame = cap2.read()\n",
    "    if not ret: break\n",
    "        \n",
    "    cropped_image = region_of_interest(frame,np.array([region_of_interest_vertices], np.int32),)\n",
    "\n",
    "    out.write(cropped_image)\n",
    "    cv2.imshow('frame',cropped_image)\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'): break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "out.release()\n",
    "cap2.release()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e9a0db-1dda-45ec-8f86-7dfac37bb562",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
